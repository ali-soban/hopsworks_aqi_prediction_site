# This file must be saved in: .github/workflows/feature_pipeline.yml
# This script runs hourly to fetch new data and feed the Hopsworks Feature Store.

name: Hourly Feature Update (to Hopsworks)

on:
  schedule:
    - cron: '0 * * * *' # Runs at the start of every hour
  workflow_dispatch: # Allows you to run it manually from the Actions tab

jobs:
  update-features-hopsworks:
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # *** UPDATED THIS LINE to include [python] extras ***
          pip install pandas requests numpy "hopsworks[python]"

      - name: Run feature pipeline script
        env:
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          HOPSWORKS_PROJECT_NAME: ${{ secrets.HOPSWORKS_PROJECT_NAME }}
        run: |
          python - <<EOF
          import pandas as pd
          import numpy as np
          import requests
          import warnings
          import datetime
          import hopsworks
          import os

          warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)
          warnings.filterwarnings('ignore', category=UserWarning)

          print("--- STEP 1: DEFINE CONSTANTS AND FUNCTIONS ---")

          # --- AQI Calculation Constants ---
          PM25_BREAKPOINTS = [((0.0, 12.0), (0, 50)), ((12.1, 35.4), (51, 100)), ((35.5, 55.4), (101, 150)), ((55.5, 150.4), (151, 200)), ((150.5, 250.4), (201, 300)), ((250.5, 350.4), (301, 400)), ((350.5, 500.4), (401, 500)),]
          PM10_BREAKPOINTS = [((0, 54), (0, 50)), ((55, 154), (51, 100)), ((155, 254), (101, 150)), ((255, 354), (151, 200)), ((355, 424), (201, 300)), ((425, 504), (301, 400)), ((505, 604), (401, 500)),]
          O3_BREAKPOINTS = [((0, 106), (0, 50)), ((107, 137), (51, 100)), ((138, 167), (101, 150)), ((168, 206), (151, 200)), ((207, 392), (201, 300))]
          CO_BREAKPOINTS = [((0, 5040), (0, 50)), ((5041, 10760), (51, 100)), ((10761, 14200), (101, 150)), ((14201, 17600), (151, 200)), ((17601, 34800), (201, 300)), ((34801, 46300), (301, 400)), ((46301, 57800), (401, 500)),]
          SO2_BREAKPOINTS = [((0, 92), (0, 50)), ((93, 197), (51, 100)), ((198, 482), (101, 150)), ((483, 795), (151, 200)),]
          NO2_BREAKPOINTS = [((0, 100), (0, 50)), ((101, 188), (51, 100)), ((189, 677), (101, 150)), ((678, 1220), (151, 200)), ((1221, 2330), (201, 300)), ((2331, 3080), (301, 400)), ((3081, 3835), (401, 500)),]

          def calculate_sub_index(concentration, breakpoints):
              if not isinstance(concentration, (int, float, np.number)) or pd.isna(concentration): return np.nan
              for i, ((cl, ch), (al, ah)) in enumerate(breakpoints):
                  if i == 0 and cl <= concentration <= ch:
                      return round(((ah - al) / (ch - cl)) * (concentration - cl) + al) if ch != cl else float(al)
                  elif i > 0 and cl < concentration <= ch:
                      return round(((ah - al) / (ch - cl)) * (concentration - cl) + al) if ch != cl else float(al)
              if breakpoints and concentration > breakpoints[-1][0][1]:
                  return breakpoints[-1][1][1] if len(breakpoints[-1]) > 1 and len(breakpoints[-1][1]) > 1 else 500
              return np.nan

          def create_features(df_raw):
              df = df_raw.copy()
              if not isinstance(df.index, pd.DatetimeIndex):
                  print("ERROR: Index is not DatetimeIndex.")
                  return None, None
              
              pollutant_cols = ['pm10', 'pm2_5', 'carbon_monoxide', 'nitrogen_dioxide', 'sulphur_dioxide', 'ozone']
              for col in pollutant_cols:
                  if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')
                  else: df[col] = np.nan

              df['pm2_5_subindex'] = df['pm2_5'].apply(lambda x: calculate_sub_index(x, PM25_BREAKPOINTS))
              df['pm10_subindex'] = df['pm10'].apply(lambda x: calculate_sub_index(x, PM10_BREAKPOINTS))
              df['ozone_subindex'] = df['ozone'].apply(lambda x: calculate_sub_index(x, O3_BREAKPOINTS))
              df['carbon_monoxide_subindex'] = df['carbon_monoxide'].apply(lambda x: calculate_sub_index(x, CO_BREAKPOINTS))
              df['sulphur_dioxide_subindex'] = df['sulphur_dioxide'].apply(lambda x: calculate_sub_index(x, SO2_BREAKPOINTS))
              df['nitrogen_dioxide_subindex'] = df['nitrogen_dioxide'].apply(lambda x: calculate_sub_index(x, NO2_BREAKPOINTS))

              sub_indices_cols = ['pm2_5_subindex', 'pm10_subindex', 'ozone_subindex', 'carbon_monoxide_subindex', 'sulphur_dioxide_subindex', 'nitrogen_dioxide_subindex']
              for col in sub_indices_cols:
                  if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')

              df['aqi'] = df[sub_indices_cols].max(axis=1, skipna=True)
              df_features = df.copy()

              df_features['hour_sin'] = np.sin(2 * np.pi * df_features.index.hour / 23.0)
              df_features['hour_cos'] = np.cos(2 * np.pi * df_features.index.hour / 23.0)
              df_features['day_of_week_sin'] = np.sin(2 * np.pi * df_features.index.dayofweek / 6.0)
              df_features['day_of_week_cos'] = np.cos(2 * np.pi * df_features.index.dayofweek / 6.0)
              df_features['month_sin'] = np.sin(2 * np.pi * df_features.index.month / 12.0)
              df_features['month_cos'] = np.cos(2 * np.pi * df_features.index.month / 12.0)
              
              weather_cols_to_lag = ['temperature_2m', 'relative_humidity_2m', 'wind_speed_10m']
              for col in weather_cols_to_lag:
                  if col not in df_features.columns: df_features[col] = np.nan
              
              df_features['aqi_lag_1hr'] = df_features['aqi'].shift(1)
              df_features['aqi_lag_3hr'] = df_features['aqi'].shift(3)
              df_features['aqi_lag_24hr'] = df_features['aqi'].shift(24)
              df_features['aqi_lag_72hr'] = df_features['aqi'].shift(72)
              df_features['temp_lag_1hr'] = df_features['temperature_2m'].shift(1)
              df_features['humidity_lag_1hr'] = df_features['relative_humidity_2m'].shift(1)
              df_features['wind_speed_lag_1hr'] = df_features['wind_speed_10m'].shift(1)
              df_features['aqi_rolling_3hr'] = df_features['aqi'].shift(1).rolling(window=3).mean()
              df_features['aqi_change_1hr'] = df_features['aqi'].shift(1) - df_features['aqi'].shift(2)
              df_features['target_aqi'] = df_features['aqi'].shift(-72) 
              
              return df_features # Return the full feature-engineered dataframe
          
          print("--- STEP 2: DATA FETCHING ---")
          
          latitude = 24.86
          longitude = 67.01
          fetch_days_past = 10
          fetch_days_future = 3
          now_utc = pd.to_datetime("now", utc=True)

          start_date_aq = (now_utc - pd.Timedelta(days=fetch_days_past)).strftime('%Y-%m-%d')
          end_date_aq = now_utc.strftime('%Y-%m-%d')
          start_date_weather = start_date_aq
          end_date_weather = (now_utc + pd.Timedelta(days=fetch_days_future)).strftime('%Y-%m-%d')
          
          print(f"Fetching data for range: {start_date_weather} to {end_date_weather}")

          # Fetch Air Quality Data
          try:
              aq_response = requests.get(
                  "https://air-quality-api.open-meteo.com/v1/air-quality",
                  params={
                      "latitude": latitude, "longitude": longitude,
                      "start_date": start_date_aq, "end_date": end_date_aq,
                      "hourly": "pm10,pm2_5,carbon_monoxide,nitrogen_dioxide,sulphur_dioxide,ozone",
                      "timezone": "UTC"
                  }
              )
              aq_response.raise_for_status()
              aq_data = aq_response.json()
              aq_df = pd.DataFrame(aq_data['hourly'])
              aq_df['time'] = pd.to_datetime(aq_df['time'], utc=True)
              aq_df.set_index('time', inplace=True)
          except Exception as e:
              print(f"ERROR: Failed to fetch air quality data: {e}")
              exit(1)

          # Fetch Weather Data (Past + Future)
          all_weather_dfs = []
          weather_params = {
              "latitude": latitude, "longitude": longitude,
              "hourly": "temperature_2m,relative_humidity_2m,precipitation,wind_speed_10m,wind_direction_10m",
              "timezone": "UTC"
          }
          try:
              end_date_past_weather = (now_utc - pd.Timedelta(days=1)).strftime('%Y-%m-%d')
              if start_date_weather <= end_date_past_weather:
                  past_params = {**weather_params, "start_date": start_date_weather, "end_date": end_date_past_weather}
                  past_weather_response = requests.get("https://archive-api.open-meteo.com/v1/archive", params=past_params)
                  past_weather_response.raise_for_status()
                  past_weather_data = past_weather_response.json()
                  if 'hourly' in past_weather_data:
                      past_weather_df = pd.DataFrame(past_weather_data['hourly'])
                      past_weather_df['time'] = pd.to_datetime(past_weather_df['time'], utc=True)
                      all_weather_dfs.append(past_weather_df)

              end_date_weather_ts = pd.to_datetime(end_date_weather, utc=True)
              forecast_days_needed = (end_date_weather_ts - now_utc.normalize()).days + 1
              future_params = {**weather_params, "forecast_days": max(1, forecast_days_needed)}
              future_weather_response = requests.get("https://api.open-meteo.com/v1/forecast", params=future_params)
              future_weather_response.raise_for_status()
              future_weather_data = future_weather_response.json()
              if 'hourly' in future_weather_data:
                  future_weather_df = pd.DataFrame(future_weather_data['hourly'])
                  future_weather_df['time'] = pd.to_datetime(future_weather_df['time'], utc=True)
                  all_weather_dfs.append(future_weather_df)
              
              if not all_weather_dfs:
                  raise ValueError("No weather data could be fetched.")
              
              weather_df_combined = pd.concat(all_weather_dfs, ignore_index=True)
              weather_df_combined.set_index('time', inplace=True)
              weather_df = weather_df_combined[~weather_df_combined.index.duplicated(keep='first')].sort_index()

          except Exception as e:
              print(f"ERROR: Failed to fetch weather data: {e}")
              exit(1)

          df_combined = aq_df.join(weather_df, how='outer').sort_index()
          if df_combined.index.tz is None:
              df_combined = df_combined.tz_localize('UTC')
          elif df_combined.index.tz != datetime.timezone.utc:
              df_combined = df_combined.tz_convert('UTC')
          
          print(f"Data fetched and combined. Shape: {df_combined.shape}")

          print("\n--- STEP 3: FEATURE ENGINEERING ---")
          df_features = create_features(df_combined)
          if df_features is None:
              print("ERROR: Feature creation failed.")
              exit(1)
          
          df_features['event_time'] = (df_features.index.astype('int64') // 10**9).astype(int)
          
          # *** FIX 1: DEFINE THE FINAL SCHEMA WE WANT TO SAVE ***
          # This list contains ALL columns for the Feature Group
          final_feature_columns = [
              'event_time', # Primary Key
              'aqi', 'target_aqi', # Target and label
              
              # Cyclical Time Features
              'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos', 'month_sin', 'month_cos',
              
              # Weather Features
              'temperature_2m', 'relative_humidity_2m', 'precipitation', 'wind_speed_10m', 'wind_direction_10m',
              
              # Lagged AQI Features
              'aqi_lag_1hr', 'aqi_lag_3hr', 'aqi_lag_24hr', 'aqi_lag_72hr',
              
              # Lagged Weather Features
              'temp_lag_1hr', 'humidity_lag_1hr', 'wind_speed_lag_1hr',
              
              # Rolling/Change Features
              'aqi_rolling_3hr', 'aqi_change_1hr'
          ]
          
          # Select ONLY these columns
          df_to_insert = df_features[final_feature_columns]
          
          # *** FIX 2: FIX THE DATA TYPE FOR HUMIDITY ***
          df_to_insert['relative_humidity_2m'] = df_to_insert['relative_humidity_2m'].astype(float)
          
          # Drop rows with NaN in critical lag columns before inserting
          df_to_insert.dropna(
              subset=['aqi_lag_1hr', 'aqi_lag_24hr', 'aqi_lag_72hr', 'aqi_rolling_3hr'], 
              inplace=True
          )
          
          if df_to_insert.empty:
              print("ERROR: No data left after feature engineering and NaN drop.")
              exit(1)
          
          print(f"Features engineered. Final shape to insert: {df_to_insert.shape}")
          print("Final columns:", df_to_insert.columns.tolist())

          print("\n--- STEP 4: HOPSWORKS INSERT ---")
          try:
              print("Connecting to Hopsworks...")
              project = hopsworks.login(
                  api_key_value=os.environ['HOPSWORKS_API_KEY'],
                  project=os.environ['HOPSWORKS_PROJECT_NAME']
              )
              fs = project.get_feature_store()

              FEATURE_GROUP_NAME = "karachi_aqi_features"
              FEATURE_GROUP_VERSION = 1
              
              print(f"Getting or creating Feature Group: {FEATURE_GROUP_NAME} v{FEATURE_GROUP_VERSION}")
              
              # *** FIX 3: USE get_or_create_feature_group ***
              # This will create the FG with the *correct* schema from our DataFrame
              aqi_fg = fs.get_or_create_feature_group(
                  name=FEATURE_GROUP_NAME,
                  version=FEATURE_GROUP_VERSION,
                  primary_key=['event_time'],
                  event_time='event_time',
                  description="Hourly features for Karachi AQI prediction"
              )
              
              print(f"Inserting {len(df_to_insert)} rows into Hopsworks...")
              aqi_fg.insert(df_to_insert, write_options={"wait_for_job": True})
              print("Data insertion complete.")

          except Exception as e:
              print(f"ERROR: Could not insert data into Hopsworks: {e}")
              exit(1)

          print("\n--- FEATURE PIPELINE SCRIPT COMPLETED ---")
          EOF